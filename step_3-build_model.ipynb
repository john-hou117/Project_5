{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain and Data\n",
    "\n",
    "Domain: We will use our machine learning pipelines to build models that utilize different transformers and parameters.\n",
    "\n",
    "Data: Our dataset is the same from Steps 1 and 2, the MADELON dataset. \n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Our goal is to build more robust models than those in Step 1 or Step 2. We also wish to find the optimal parameters that will yield better performing (in terms of both accuracy and salient feature selection) models. Finally, we want to compare the performance of models against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import our wrapper functions from the project_5.py in our lib\n",
    "from lib.project_5 import load_data_from_database, add_to_process_list, make_data_dict, validate_dictionary, general_model, general_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load our data, from the database, into a DataFrame\n",
    "madelon_df = load_data_from_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 501)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure our data was loaded correctly. Our DataFrame should have 2000 rows and 501 columns\n",
    "madelon_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Statement\n",
    "\n",
    "We will use SelectKBest as our transformer. The models we will use are Logistic Regression KNeighborsClassifier. To select the optimal parameters for each of these models, we will run a GridSearchCV (cross validated grid search) for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform using SelectKBest, then run Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a data dictionary from our DataFrame\n",
    "data_dictionary = make_data_dict(madelon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[495, 523, 536, ..., 459, 543, 491],\n",
       "        [490, 461, 611, ..., 426, 614, 436],\n",
       "        [517, 706, 417, ..., 497, 368, 547],\n",
       "        ..., \n",
       "        [531, 421, 542, ..., 430, 547, 597],\n",
       "        [439, 577, 450, ..., 462, 426, 363],\n",
       "        [469, 486, 551, ..., 434, 558, 417]]),\n",
       " 'X_train': array([[551, 518, 559, ..., 441, 568, 417],\n",
       "        [463, 567, 454, ..., 502, 433, 532],\n",
       "        [561, 511, 509, ..., 475, 505, 410],\n",
       "        ..., \n",
       "        [544, 645, 448, ..., 444, 423, 548],\n",
       "        [472, 416, 534, ..., 465, 537, 384],\n",
       "        [417, 432, 512, ..., 509, 506, 649]]),\n",
       " 'processes': [SelectKBest(k=10, score_func=<function f_classif at 0x112bdf9b0>)],\n",
       " 'y_test': index\n",
       " 1616    1\n",
       " 1878   -1\n",
       " 446     1\n",
       " 1421   -1\n",
       " 89     -1\n",
       " 805     1\n",
       " 587     1\n",
       " 738     1\n",
       " 989    -1\n",
       " 447    -1\n",
       " 555    -1\n",
       " 190    -1\n",
       " 931    -1\n",
       " 405    -1\n",
       " 1887   -1\n",
       " 71      1\n",
       " 835     1\n",
       " 1496    1\n",
       " 813     1\n",
       " 1373   -1\n",
       " 1622    1\n",
       " 1790   -1\n",
       " 1235   -1\n",
       " 1650   -1\n",
       " 783    -1\n",
       " 1699    1\n",
       " 536    -1\n",
       " 1053    1\n",
       " 1853    1\n",
       " 1837    1\n",
       "        ..\n",
       " 972    -1\n",
       " 1813   -1\n",
       " 304     1\n",
       " 1074   -1\n",
       " 1833    1\n",
       " 1510    1\n",
       " 234    -1\n",
       " 644    -1\n",
       " 1998    1\n",
       " 1932   -1\n",
       " 648    -1\n",
       " 385     1\n",
       " 398     1\n",
       " 152    -1\n",
       " 1383   -1\n",
       " 550    -1\n",
       " 752     1\n",
       " 1241    1\n",
       " 556    -1\n",
       " 1908   -1\n",
       " 1380   -1\n",
       " 932    -1\n",
       " 448    -1\n",
       " 1588    1\n",
       " 498    -1\n",
       " 1927   -1\n",
       " 208    -1\n",
       " 1281    1\n",
       " 1132   -1\n",
       " 1397    1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': index\n",
       " 545     1\n",
       " 592    -1\n",
       " 1726    1\n",
       " 1148    1\n",
       " 1595    1\n",
       " 337     1\n",
       " 1120    1\n",
       " 694    -1\n",
       " 1544    1\n",
       " 1356    1\n",
       " 1805   -1\n",
       " 508    -1\n",
       " 455    -1\n",
       " 971    -1\n",
       " 509     1\n",
       " 1693    1\n",
       " 6       1\n",
       " 351     1\n",
       " 1298    1\n",
       " 440     1\n",
       " 1662   -1\n",
       " 1412    1\n",
       " 1702    1\n",
       " 1563    1\n",
       " 1401    1\n",
       " 1263    1\n",
       " 1859   -1\n",
       " 361    -1\n",
       " 1890   -1\n",
       " 959     1\n",
       "        ..\n",
       " 757     1\n",
       " 1769   -1\n",
       " 1956   -1\n",
       " 675     1\n",
       " 1934    1\n",
       " 1092   -1\n",
       " 1971   -1\n",
       " 505    -1\n",
       " 330     1\n",
       " 1519   -1\n",
       " 156     1\n",
       " 1657   -1\n",
       " 349     1\n",
       " 1338   -1\n",
       " 395     1\n",
       " 1223    1\n",
       " 884    -1\n",
       " 1961    1\n",
       " 1456   -1\n",
       " 423    -1\n",
       " 1855   -1\n",
       " 1444    1\n",
       " 61      1\n",
       " 918    -1\n",
       " 1618   -1\n",
       " 1464   -1\n",
       " 1198    1\n",
       " 580    -1\n",
       " 462     1\n",
       " 772    -1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use SelectKBest as our transformer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "selectkbest = general_transformer(SelectKBest(), data_dictionary)\n",
    "selectkbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[495, 523, 536, ..., 459, 543, 491],\n",
       "        [490, 461, 611, ..., 426, 614, 436],\n",
       "        [517, 706, 417, ..., 497, 368, 547],\n",
       "        ..., \n",
       "        [531, 421, 542, ..., 430, 547, 597],\n",
       "        [439, 577, 450, ..., 462, 426, 363],\n",
       "        [469, 486, 551, ..., 434, 558, 417]]),\n",
       " 'X_train': array([[551, 518, 559, ..., 441, 568, 417],\n",
       "        [463, 567, 454, ..., 502, 433, 532],\n",
       "        [561, 511, 509, ..., 475, 505, 410],\n",
       "        ..., \n",
       "        [544, 645, 448, ..., 444, 423, 548],\n",
       "        [472, 416, 534, ..., 465, 537, 384],\n",
       "        [417, 432, 512, ..., 509, 506, 649]]),\n",
       " 'coef_': array([[-0.00013693, -0.0014875 , -0.00717311,  0.00066741,  0.00400343,\n",
       "          0.00299242, -0.00144017, -0.00638096,  0.00956805,  0.00035804]]),\n",
       " 'processes': [SelectKBest(k=10, score_func=<function f_classif at 0x112bdf9b0>),\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False)],\n",
       " 'sal_features': array([[559, 566, 441, 568],\n",
       "        [454, 467, 502, 433],\n",
       "        [509, 599, 475, 505],\n",
       "        ..., \n",
       "        [448, 561, 444, 423],\n",
       "        [534, 479, 465, 537],\n",
       "        [512, 404, 509, 506]]),\n",
       " 'test_score': 0.62,\n",
       " 'train_score': 0.61357142857142855,\n",
       " 'y_test': index\n",
       " 1616    1\n",
       " 1878   -1\n",
       " 446     1\n",
       " 1421   -1\n",
       " 89     -1\n",
       " 805     1\n",
       " 587     1\n",
       " 738     1\n",
       " 989    -1\n",
       " 447    -1\n",
       " 555    -1\n",
       " 190    -1\n",
       " 931    -1\n",
       " 405    -1\n",
       " 1887   -1\n",
       " 71      1\n",
       " 835     1\n",
       " 1496    1\n",
       " 813     1\n",
       " 1373   -1\n",
       " 1622    1\n",
       " 1790   -1\n",
       " 1235   -1\n",
       " 1650   -1\n",
       " 783    -1\n",
       " 1699    1\n",
       " 536    -1\n",
       " 1053    1\n",
       " 1853    1\n",
       " 1837    1\n",
       "        ..\n",
       " 972    -1\n",
       " 1813   -1\n",
       " 304     1\n",
       " 1074   -1\n",
       " 1833    1\n",
       " 1510    1\n",
       " 234    -1\n",
       " 644    -1\n",
       " 1998    1\n",
       " 1932   -1\n",
       " 648    -1\n",
       " 385     1\n",
       " 398     1\n",
       " 152    -1\n",
       " 1383   -1\n",
       " 550    -1\n",
       " 752     1\n",
       " 1241    1\n",
       " 556    -1\n",
       " 1908   -1\n",
       " 1380   -1\n",
       " 932    -1\n",
       " 448    -1\n",
       " 1588    1\n",
       " 498    -1\n",
       " 1927   -1\n",
       " 208    -1\n",
       " 1281    1\n",
       " 1132   -1\n",
       " 1397    1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': index\n",
       " 545     1\n",
       " 592    -1\n",
       " 1726    1\n",
       " 1148    1\n",
       " 1595    1\n",
       " 337     1\n",
       " 1120    1\n",
       " 694    -1\n",
       " 1544    1\n",
       " 1356    1\n",
       " 1805   -1\n",
       " 508    -1\n",
       " 455    -1\n",
       " 971    -1\n",
       " 509     1\n",
       " 1693    1\n",
       " 6       1\n",
       " 351     1\n",
       " 1298    1\n",
       " 440     1\n",
       " 1662   -1\n",
       " 1412    1\n",
       " 1702    1\n",
       " 1563    1\n",
       " 1401    1\n",
       " 1263    1\n",
       " 1859   -1\n",
       " 361    -1\n",
       " 1890   -1\n",
       " 959     1\n",
       "        ..\n",
       " 757     1\n",
       " 1769   -1\n",
       " 1956   -1\n",
       " 675     1\n",
       " 1934    1\n",
       " 1092   -1\n",
       " 1971   -1\n",
       " 505    -1\n",
       " 330     1\n",
       " 1519   -1\n",
       " 156     1\n",
       " 1657   -1\n",
       " 349     1\n",
       " 1338   -1\n",
       " 395     1\n",
       " 1223    1\n",
       " 884    -1\n",
       " 1961    1\n",
       " 1456   -1\n",
       " 423    -1\n",
       " 1855   -1\n",
       " 1444    1\n",
       " 61      1\n",
       " 918    -1\n",
       " 1618   -1\n",
       " 1464   -1\n",
       " 1198    1\n",
       " 580    -1\n",
       " 462     1\n",
       " 772    -1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "selectkbest_scored = general_model(LogisticRegression(), selectkbest)\n",
    "selectkbest_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many salient features are remaining\n",
    "selectkbest_scored['sal_features'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_491</th>\n",
       "      <th>feat_492</th>\n",
       "      <th>feat_493</th>\n",
       "      <th>feat_494</th>\n",
       "      <th>feat_495</th>\n",
       "      <th>feat_496</th>\n",
       "      <th>feat_497</th>\n",
       "      <th>feat_498</th>\n",
       "      <th>feat_499</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  feat_006  \\\n",
       "index                                                                         \n",
       "0           485       477       537       479       452       471       491   \n",
       "1           483       458       460       487       587       475       526   \n",
       "2           487       542       499       468       448       471       442   \n",
       "3           480       491       510       485       495       472       417   \n",
       "4           484       502       528       489       466       481       402   \n",
       "\n",
       "       feat_007  feat_008  feat_009  ...    feat_491  feat_492  feat_493  \\\n",
       "index                                ...                                   \n",
       "0           476       475       473  ...         481       477       485   \n",
       "1           479       485       469  ...         478       487       338   \n",
       "2           478       480       477  ...         481       492       650   \n",
       "3           474       502       476  ...         480       474       572   \n",
       "4           478       487       468  ...         479       452       435   \n",
       "\n",
       "       feat_494  feat_495  feat_496  feat_497  feat_498  feat_499  label  \n",
       "index                                                                     \n",
       "0           511       485       481       479       475       496     -1  \n",
       "1           513       486       483       492       510       517     -1  \n",
       "2           506       501       480       489       499       498     -1  \n",
       "3           454       469       475       482       494       461      1  \n",
       "4           486       508       481       504       495       511      1  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madelon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform using SelectKBest, then run KNearestNeighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a data dictionary from our DataFrame\n",
    "data_dictionary_2 = make_data_dict(madelon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[406, 440, 315, ..., 391, 529, 543],\n",
       "        [528, 445, 563, ..., 551, 487, 553],\n",
       "        [464, 468, 363, ..., 463, 467, 571],\n",
       "        ..., \n",
       "        [468, 300, 661, ..., 472, 492, 591],\n",
       "        [521, 352, 620, ..., 535, 550, 553],\n",
       "        [453, 534, 374, ..., 458, 428, 549]]),\n",
       " 'X_train': array([[445, 495, 355, ..., 431, 502, 501],\n",
       "        [438, 481, 494, ..., 440, 320, 555],\n",
       "        [465, 324, 567, ..., 469, 560, 629],\n",
       "        ..., \n",
       "        [520, 404, 593, ..., 524, 572, 512],\n",
       "        [439, 494, 484, ..., 440, 581, 429],\n",
       "        [430, 409, 491, ..., 443, 568, 521]]),\n",
       " 'processes': [SelectKBest(k=10, score_func=<function f_classif at 0x112bdf9b0>)],\n",
       " 'y_test': index\n",
       " 1358    1\n",
       " 1885    1\n",
       " 734    -1\n",
       " 870     1\n",
       " 644    -1\n",
       " 1581   -1\n",
       " 85     -1\n",
       " 978    -1\n",
       " 244    -1\n",
       " 1235   -1\n",
       " 1468    1\n",
       " 1674    1\n",
       " 349     1\n",
       " 1640    1\n",
       " 1286    1\n",
       " 447    -1\n",
       " 1633   -1\n",
       " 42      1\n",
       " 92     -1\n",
       " 1232    1\n",
       " 1028    1\n",
       " 1751    1\n",
       " 1778   -1\n",
       " 1652    1\n",
       " 448    -1\n",
       " 1952    1\n",
       " 247    -1\n",
       " 551     1\n",
       " 1799   -1\n",
       " 685    -1\n",
       "        ..\n",
       " 1643    1\n",
       " 1365    1\n",
       " 1527   -1\n",
       " 1123   -1\n",
       " 183    -1\n",
       " 1515   -1\n",
       " 803     1\n",
       " 1790   -1\n",
       " 418    -1\n",
       " 446     1\n",
       " 1993   -1\n",
       " 1682    1\n",
       " 151    -1\n",
       " 907     1\n",
       " 1453   -1\n",
       " 1614   -1\n",
       " 1482   -1\n",
       " 1174   -1\n",
       " 1700    1\n",
       " 543    -1\n",
       " 119     1\n",
       " 989    -1\n",
       " 1164   -1\n",
       " 1016   -1\n",
       " 1945    1\n",
       " 776    -1\n",
       " 1870    1\n",
       " 757     1\n",
       " 461    -1\n",
       " 1925   -1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': index\n",
       " 186    -1\n",
       " 1131    1\n",
       " 1813   -1\n",
       " 1308    1\n",
       " 227     1\n",
       " 838     1\n",
       " 879     1\n",
       " 1761   -1\n",
       " 749    -1\n",
       " 389    -1\n",
       " 1161   -1\n",
       " 35     -1\n",
       " 1831    1\n",
       " 1565   -1\n",
       " 793    -1\n",
       " 804    -1\n",
       " 914    -1\n",
       " 497     1\n",
       " 1001   -1\n",
       " 856    -1\n",
       " 457     1\n",
       " 1355   -1\n",
       " 709     1\n",
       " 1405    1\n",
       " 674    -1\n",
       " 335     1\n",
       " 1008   -1\n",
       " 1396    1\n",
       " 1419    1\n",
       " 965     1\n",
       "        ..\n",
       " 1449   -1\n",
       " 986     1\n",
       " 1911   -1\n",
       " 1374    1\n",
       " 500    -1\n",
       " 625     1\n",
       " 808     1\n",
       " 1198    1\n",
       " 26      1\n",
       " 786     1\n",
       " 1520   -1\n",
       " 718     1\n",
       " 1967    1\n",
       " 561     1\n",
       " 1069    1\n",
       " 1115   -1\n",
       " 1838    1\n",
       " 1781   -1\n",
       " 841     1\n",
       " 356     1\n",
       " 1274   -1\n",
       " 1463    1\n",
       " 1241    1\n",
       " 431    -1\n",
       " 1823   -1\n",
       " 1775   -1\n",
       " 1765   -1\n",
       " 1398   -1\n",
       " 955    -1\n",
       " 443    -1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use SelectKBest as our transformer\n",
    "selectkbest_2 = general_transformer(SelectKBest(), data_dictionary_2)\n",
    "selectkbest_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[406, 440, 315, ..., 391, 529, 543],\n",
       "        [528, 445, 563, ..., 551, 487, 553],\n",
       "        [464, 468, 363, ..., 463, 467, 571],\n",
       "        ..., \n",
       "        [468, 300, 661, ..., 472, 492, 591],\n",
       "        [521, 352, 620, ..., 535, 550, 553],\n",
       "        [453, 534, 374, ..., 458, 428, 549]]),\n",
       " 'X_train': array([[445, 495, 355, ..., 431, 502, 501],\n",
       "        [438, 481, 494, ..., 440, 320, 555],\n",
       "        [465, 324, 567, ..., 469, 560, 629],\n",
       "        ..., \n",
       "        [520, 404, 593, ..., 524, 572, 512],\n",
       "        [439, 494, 484, ..., 440, 581, 429],\n",
       "        [430, 409, 491, ..., 443, 568, 521]]),\n",
       " 'processes': [SelectKBest(k=10, score_func=<function f_classif at 0x112bdf9b0>),\n",
       "  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "             weights='uniform')],\n",
       " 'test_score': 0.84666666666666668,\n",
       " 'train_score': 0.90357142857142858,\n",
       " 'y_test': index\n",
       " 1358    1\n",
       " 1885    1\n",
       " 734    -1\n",
       " 870     1\n",
       " 644    -1\n",
       " 1581   -1\n",
       " 85     -1\n",
       " 978    -1\n",
       " 244    -1\n",
       " 1235   -1\n",
       " 1468    1\n",
       " 1674    1\n",
       " 349     1\n",
       " 1640    1\n",
       " 1286    1\n",
       " 447    -1\n",
       " 1633   -1\n",
       " 42      1\n",
       " 92     -1\n",
       " 1232    1\n",
       " 1028    1\n",
       " 1751    1\n",
       " 1778   -1\n",
       " 1652    1\n",
       " 448    -1\n",
       " 1952    1\n",
       " 247    -1\n",
       " 551     1\n",
       " 1799   -1\n",
       " 685    -1\n",
       "        ..\n",
       " 1643    1\n",
       " 1365    1\n",
       " 1527   -1\n",
       " 1123   -1\n",
       " 183    -1\n",
       " 1515   -1\n",
       " 803     1\n",
       " 1790   -1\n",
       " 418    -1\n",
       " 446     1\n",
       " 1993   -1\n",
       " 1682    1\n",
       " 151    -1\n",
       " 907     1\n",
       " 1453   -1\n",
       " 1614   -1\n",
       " 1482   -1\n",
       " 1174   -1\n",
       " 1700    1\n",
       " 543    -1\n",
       " 119     1\n",
       " 989    -1\n",
       " 1164   -1\n",
       " 1016   -1\n",
       " 1945    1\n",
       " 776    -1\n",
       " 1870    1\n",
       " 757     1\n",
       " 461    -1\n",
       " 1925   -1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': index\n",
       " 186    -1\n",
       " 1131    1\n",
       " 1813   -1\n",
       " 1308    1\n",
       " 227     1\n",
       " 838     1\n",
       " 879     1\n",
       " 1761   -1\n",
       " 749    -1\n",
       " 389    -1\n",
       " 1161   -1\n",
       " 35     -1\n",
       " 1831    1\n",
       " 1565   -1\n",
       " 793    -1\n",
       " 804    -1\n",
       " 914    -1\n",
       " 497     1\n",
       " 1001   -1\n",
       " 856    -1\n",
       " 457     1\n",
       " 1355   -1\n",
       " 709     1\n",
       " 1405    1\n",
       " 674    -1\n",
       " 335     1\n",
       " 1008   -1\n",
       " 1396    1\n",
       " 1419    1\n",
       " 965     1\n",
       "        ..\n",
       " 1449   -1\n",
       " 986     1\n",
       " 1911   -1\n",
       " 1374    1\n",
       " 500    -1\n",
       " 625     1\n",
       " 808     1\n",
       " 1198    1\n",
       " 26      1\n",
       " 786     1\n",
       " 1520   -1\n",
       " 718     1\n",
       " 1967    1\n",
       " 561     1\n",
       " 1069    1\n",
       " 1115   -1\n",
       " 1838    1\n",
       " 1781   -1\n",
       " 841     1\n",
       " 356     1\n",
       " 1274   -1\n",
       " 1463    1\n",
       " 1241    1\n",
       " 431    -1\n",
       " 1823   -1\n",
       " 1775   -1\n",
       " 1765   -1\n",
       " 1398   -1\n",
       " 955    -1\n",
       " 443    -1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = general_model(KNeighborsClassifier(), selectkbest_2)\n",
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearchCV for Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Best Score: 0.5421\n",
      "Grid Search Best Parameter for C: \n",
      "{'C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_range = [0.0001, 0.001, 0.01, .1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'C': param_range}]\n",
    "\n",
    "gs = GridSearchCV(estimator=lr, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "gs = gs.fit(data_dictionary['X_train'], data_dictionary['y_train'])\n",
    "\n",
    "print('Grid Search Best Score: %.4f' % gs.best_score_)\n",
    "print('Grid Search Best Parameter for C: ')\n",
    "print gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearchCV for KNeighborsClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Best Score: 0.7157\n",
      "Grid Search Best Parameter for C: \n",
      "{'n_neighbors': 17}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "\n",
    "param_range = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "param_grid = [{'n_neighbors': param_range}]\n",
    "\n",
    "gs2 = GridSearchCV(estimator=knc, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "gs2 = gs2.fit(data_dictionary['X_train'], data_dictionary['y_train'])\n",
    "\n",
    "print('Grid Search Best Score: %.4f' % gs2.best_score_)\n",
    "print('Grid Search Best Parameter for n_neighbors: ')\n",
    "print gs2.best_params_\n",
    "print gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric\n",
    "\n",
    "For feature selection, we will use the number of features left (i.e. not removed) as our metric.\n",
    "\n",
    "The other obvious metric for our models will be their accuracy score (test score).\n",
    "\n",
    "### Benchmark\n",
    "\n",
    "For relevant feature selection, we strive to do better than 463 features (which is what we were left with in Step 2 when utilizing Logistic Regression with Lasso).\n",
    "\n",
    "For accuracy, we hope to do better than the 57% benchmark that was set in Step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "For relevant feature selection, we were left with just 4 features. It appears that we did better than our previous number of 463 features. Unfortunately, since we know that the actual number of relevant features is higher than 4, and that our test score was only 62% with this combination of SelectKBest and LogisticRegression, it would seem that we eliminated informative features as well.\n",
    "\n",
    "For our accuracy, both our Logistic Regression and our KNeighborsClassifier beat our benchmark of 57% by posting test scores of 62% and 84%, respectively. That is the good news.\n",
    "\n",
    "Here is the bad news: both our GridSearchCVs, which I expected to outperform any of our previous models, actually did worse when compared to their respective model. The GridSearchCV for Logistic Regression scored a 54% (which is worse than both our benchmark of 57% AND the SelectKBest/Logistic Regression combination, which scored 62%). The GridSearchCV for our KNeighborsClassifier also performed significantly worse than our standard SelectKBest/KNeighborsClassifier combination (71% versus 84%). It is quite possible that I made errors in implementing the GridSearchCV, for that is the only reason I can come up with for these strange results."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
